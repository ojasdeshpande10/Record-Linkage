{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 381 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ojas_d/anaconda3/lib/python3.7/site-packages (from python-Levenshtein) (45.2.0.post20200210)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=183203 sha256=868e3cde22c9690e9dc85305cfde5b8d471607893121c13a68c7ba72040539f4\n",
      "  Stored in directory: /home/ojas_d/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Class for extracting the company names from case documents\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from pandas import *\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "class extractMetadata():\n",
    "    def __init__(self, fpath):\n",
    "        with open(fpath, 'r') as f:\n",
    "            self.soup = BeautifulSoup(f.read(), 'html.parser').find('div', attrs={'class':\"judgments\"})\n",
    "        if(self.soup):\n",
    "            self.case_text = self.soup.text\n",
    "            \n",
    "        else:\n",
    "            self.case_text=''\n",
    "        \n",
    "\n",
    "    def null_check(self, soup_item, attr):\n",
    "        if attr=='text':\n",
    "            try:\n",
    "                return soup_item.text\n",
    "            except:\n",
    "                return\n",
    "        else:\n",
    "            return soup_item.find(attr)\n",
    "\n",
    "\n",
    "    def get_court(self):\n",
    "        if(self.soup):\n",
    "            source = self.soup.find('div', attrs={'class':'docsource_main'})\n",
    "        else:\n",
    "            source=None\n",
    "        \n",
    "        self.court = self.null_check(source, 'text')\n",
    "        return self.court\n",
    "\n",
    "    def get_pre(self):\n",
    "        \n",
    "        pre = self.soup.find('pre')\n",
    "        self.pre = self.null_check(pre, 'text')\n",
    "        return self.pre\n",
    "\n",
    "    def get_title(self):\n",
    "        if(self.soup):\n",
    "            title = self.null_check(self.soup.find_all('div', attrs={'class': 'doc_title'})[-1], 'text')\n",
    "        \n",
    "        else:\n",
    "            title=None\n",
    "            \n",
    "        if(title):\n",
    "            self.title = title\n",
    "            small_title, date = title.split(' on ')\n",
    "            self.petitioner, self.respondent = small_title.split(' vs ')\n",
    "            date = dt.datetime.strptime(date.strip(), '%d %B, %Y').date()\n",
    "            self.date = dt.datetime.strftime(date, '%d-%m-%Y')\n",
    "        else:\n",
    "            self.title=None\n",
    "            self.date=None\n",
    "            self.petitioner=None\n",
    "            self.respondent=None\n",
    "        return self.title\n",
    "\n",
    "    def get_author(self):\n",
    "        # NOTE: the author could be mentioned in the pretag when listing the CORAM\n",
    "        \n",
    "        if(self.soup):\n",
    "            author = self.null_check(self.soup.find('div', attrs={'class':'doc_author'}), 'text')\n",
    "        else:\n",
    "            author=None\n",
    "            \n",
    "        \n",
    "        if author:\n",
    "            self.author = author.split('Author:')[-1]\n",
    "        else:\n",
    "            self.author = None\n",
    "        return self.author\n",
    "\n",
    "    def get_bench(self):\n",
    "        if(self.soup):\n",
    "            bench = self.null_check(self.soup.find('div', attrs={'class':'doc_bench'}), 'text')\n",
    "        else:\n",
    "            bench=None\n",
    "        if bench:\n",
    "            self.bench = bench.split('Bench:')[-1]\n",
    "        else:\n",
    "            self.bench = None\n",
    "        return self.bench\n",
    "\n",
    "    def get_eq_citations(self):\n",
    "        if(self.soup):\n",
    "            eq_citations = self.null_check(self.soup.find('div', attrs={'class':'doc_citations'}), 'text')\n",
    "        else:\n",
    "            eq_citations=None\n",
    "        \n",
    "        if eq_citations:\n",
    "            self.eq_citations = eq_citations.split('Equivalent citations:')[-1]\n",
    "        else:\n",
    "            self.eq_citations = None\n",
    "        return self.eq_citations\n",
    "\n",
    "    def get_jud_order(self):\n",
    "        # make a guess about whether the document is a judgment or an order\n",
    "        # 0 if ambiguous, 1 if judgment, -1 if order\n",
    "\n",
    "        self.jud_order = 0\n",
    "        if any([x in self.case_text for x in ['JUDGMENT', 'JUDGEMENT']]):\n",
    "            self.jud_order += 1\n",
    "\n",
    "        if 'ORDER' in self.case_text:\n",
    "            self.jud_order+=1\n",
    "        \n",
    "        return self.jud_order\n",
    "\n",
    "    def get_citations(self):\n",
    "        # note: these citations are to both cases and statutes\n",
    "        if(self.soup):\n",
    "            self.citations = [x['href'] for x in self.soup.find_all('a')]\n",
    "        else:\n",
    "            self.citations=[]\n",
    "        \n",
    "        return self.citations\n",
    "    \n",
    "    def check_petitioner_firm(self):\n",
    "        if(self.soup):\n",
    "            title = self.null_check(self.soup.find_all('div', attrs={'class': 'doc_title'})[-1], 'text')\n",
    "        \n",
    "        else:\n",
    "            title=None\n",
    "        if(title):\n",
    "            self.title=title\n",
    "            small_title, date = title.split(' on ')\n",
    "            self.petitioner, self.respondent = small_title.split(' vs ')\n",
    "            petitioner_upper=self.petitioner.upper()\n",
    "            query=petitioner_upper.split()\n",
    "            my_file = open(\"companies_keyword_list.txt\", \"r\")\n",
    "            firm_names=my_file.read()\n",
    "            if any(ext in query for ext in firm_names):\n",
    "                self.petfirm=1\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                self.petfirm=0\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            self.petfirm=0\n",
    "            \n",
    "            \n",
    "       \n",
    "        \n",
    "    def check_respondent_firm(self):\n",
    "        if(self.soup):\n",
    "            title = self.null_check(self.soup.find_all('div', attrs={'class': 'doc_title'})[-1], 'text')\n",
    "        \n",
    "        else:\n",
    "            title=None\n",
    "        if(title):\n",
    "            self.title=title\n",
    "            small_title, date = title.split(' on ')\n",
    "            self.petitioner, self.respondent = small_title.split(' vs ')\n",
    "            respondent_upper=self.respondent.upper()\n",
    "            query=respondent_upper.split()\n",
    "            my_file = open(\"companies_keyword_list.txt\", \"r\")\n",
    "            firm_names=my_file.read() \n",
    "            if any(ext in query for ext in firm_names):\n",
    "                self.resfirm=1\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                self.resfirm=0\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            self.resfirm=0\n",
    "            \n",
    "            \n",
    "    def check_petitioner_gov(self):\n",
    "        title = self.null_check(self.soup.find_all('div', attrs={'class': 'doc_title'})[-1], 'text')\n",
    "        self.title=title\n",
    "        small_title, date = title.split(' on ')\n",
    "        self.petitioner, self.respondent = small_title.split(' vs ')\n",
    "        petitioner_upper=self.petitioner.upper()\n",
    "        \n",
    "        if any(ext in petitioner_upper for ext in govt_names):\n",
    "            self.petgov=1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.petgov=0\n",
    "            \n",
    "            \n",
    "    def check_respondent_gov(self):\n",
    "        title = self.null_check(self.soup.find_all('div', attrs={'class': 'doc_title'})[-1], 'text')\n",
    "        self.title=title\n",
    "        small_title, date = title.split(' on ')\n",
    "        self.petitioner, self.respondent = small_title.split(' vs ')\n",
    "        respondent_upper=self.respondent.upper()\n",
    "        \n",
    "        if any(ext in respondent_upper for ext in govt_names):\n",
    "            self.resgov=1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.resgov=0\n",
    "        \n",
    "        \n",
    "    def preprocess(self):\n",
    "        stopwords=[\"PRIVATE\", \"PRIVATELIMITED\", \"PRIVATELIMITED.\", \"PRIVATELTD\", \"LIMITED\", \"LIMITED(OPC)\", \"LIMITED,\", \"LIMITED.\", \"LIMTED\", \"LIMTIED\",\"LTD\", \"LTD,\", \"LTD.\", \"LTD.,\",\"PVT.\", \"PVT.LTD\", \"PVT.LTD.\", \"PVTLTD\", \"PVTLTD.\"]\n",
    "        \n",
    "        \n",
    "        if self.petfirm:\n",
    "            \n",
    "            query=(self.petitioner.upper()).split()\n",
    "            resultwords  = [word for word in query if word not in stopwords]\n",
    "            result = ' '.join(resultwords)\n",
    "            self.petname=result\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            self.petname=None\n",
    "            \n",
    "        if self.resfirm:\n",
    "            \n",
    "            query=(self.respondent.upper()).split()\n",
    "            resultwords  = [word for word in query if word not in stopwords]\n",
    "            result = ' '.join(resultwords)\n",
    "            self.resname=result\n",
    "            \n",
    "        else:\n",
    "            self.resname=None\n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_all_info(self):\n",
    "        info = {}\n",
    "\n",
    "        self.get_citations()\n",
    "        self.get_jud_order()\n",
    "        self.get_eq_citations()\n",
    "        self.get_court()\n",
    "        self.get_bench()\n",
    "        self.get_author()\n",
    "        self.get_title()\n",
    "        #self.get_pre()\n",
    "        self.check_petitioner_firm()\n",
    "        self.check_respondent_firm()\n",
    "        #self.check_petitioner_gov()\n",
    "        #self.check_respondent_gov()\n",
    "        self.preprocess()\n",
    "        \n",
    "\n",
    "        info['court'] = self.court\n",
    "        info['author'] = self.author\n",
    "        info['title'] = self.title\n",
    "        info['petitioner'] = self.petitioner\n",
    "        info['respondent'] = self.respondent\n",
    "        info['doc_date'] = self.date\n",
    "        #info['pre'] = self.pre\n",
    "        info['citations'] = self.citations\n",
    "        info['eq_citations'] = self.eq_citations\n",
    "        info['judgment_order'] = self.jud_order\n",
    "        info['check_petitioner_firm']=self.petfirm\n",
    "        info['check_respondent_firm']=self.resfirm\n",
    "        info['pet_name']=self.petname\n",
    "        info['res_name']=self.resname\n",
    "        #info['check_petitioner_gov']=self.petgov\n",
    "        #info['check_respondent_gov']=self.resgov\n",
    "        return info\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dir= \"/home/ojas_d/WorldBank/delhi/2016\"\n",
    "    c=1\n",
    "    List=[]\n",
    "    List1=[]\n",
    "    for filename in os.listdir(dir):\n",
    "        \n",
    "        \n",
    "        if c==200:\n",
    "            break\n",
    "                \n",
    "        filepath=os.path.join(dir, filename)\n",
    "        myfile=Path(filepath)  \n",
    "        #print(filepath)\n",
    "        case = extractMetadata(filepath)  \n",
    "        info = case.get_all_info()\n",
    "\n",
    "        #print(info)\n",
    "        if info['check_petitioner_firm'] :\n",
    "            List1.append(info['petitioner'])\n",
    "            List.append(info['pet_name'])\n",
    "        \n",
    "        \n",
    "        if info['check_respondent_firm']:\n",
    "            List1.append(info['respondent'])\n",
    "            List.append(info['res_name'])\n",
    "        c=c+1   \n",
    "    #print(List)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7579\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "data = pd.read_excel('/home/ojas_d/WorldBank/Registered_companies/raw_data/Delhi_2016.xlsx')\n",
    "choices=data['COMPANY_NAME'].tolist()\n",
    "company_names = data['COMPANY_NAME'].tolist()\n",
    "#Removing repeated words from company names which might hinder clustering\n",
    "stopwords1=[\"PVT\",\"M\",\"S\",\"ORS\",\"ANR\",\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"the\" ,\"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\",\"M/S\",\"ANR\",\"PRIVATE\", \"PRIVATELIMITED\", \"PRIVATELIMITED.\", \"PRIVATELTD\", \"LIMITED\", \"LIMITED(OPC)\", \"LIMITED,\", \"LIMITED.\", \"LIMTED\", \"LIMTIED\",\"LTD\", \"LTD,\", \"LTD.\", \"LTD.,\",\"PVT.\", \"PVT.LTD\", \"PVT.LTD.\", \"PVTLTD\", \"PVTLTD.\"]\n",
    "clean_company_names=[]\n",
    "i=0;\n",
    "for company in company_names:\n",
    "    \n",
    "    if i==20000:\n",
    "        break\n",
    "     \n",
    "    query=(company.upper()).split()\n",
    "    resultwords  = [word for word in query if word not in stopwords]\n",
    "    result = ' '.join(resultwords)\n",
    "    clean_company_names.append(result)\n",
    "    i=i+1\n",
    "    \n",
    "for i in List:\n",
    "    clean_company_names.append(i)\n",
    "print(clean_company_names)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28516"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_company_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(clean_company_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sparse_dot_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4513)\t0.6743613833261672\n",
      "  (0, 14571)\t0.7384014657883732\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELFTIMED: 0.29068851470947266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))\n",
    "import time\n",
    "t1 = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.8)\n",
    "t = time.time()-t1\n",
    "print(\"SELFTIMED:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similairity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>SEARCH BUILD TECH</td>\n",
       "      <td>SEARCH TECH INDIA</td>\n",
       "      <td>0.814534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>RAMA SANDESH DEVELOPERS PVT</td>\n",
       "      <td>RAMA SANDESH BUILDWELL</td>\n",
       "      <td>0.812467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>KULLU VALLEY LEISURE RESORTS PVT</td>\n",
       "      <td>KULLU VALLEY LEISURE RESORTS ...</td>\n",
       "      <td>0.957491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>SEVEN HEAVEN CONSTRUCTIONS</td>\n",
       "      <td>SEVEN HEAVEN IMPEX</td>\n",
       "      <td>0.841584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>ABB POWER</td>\n",
       "      <td>ABB INDIA</td>\n",
       "      <td>0.827938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>ORANGE ASHOK NORTH WIND POWER</td>\n",
       "      <td>ORANGE ASHOK WIND POWER</td>\n",
       "      <td>0.879980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>K.B. POLYCHEM (INDIA)</td>\n",
       "      <td>P D POLYCHEM</td>\n",
       "      <td>0.937767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>AMBIENCE IMPEX</td>\n",
       "      <td>AMBIENCE INDIA</td>\n",
       "      <td>0.832516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>RAJ DEVCON</td>\n",
       "      <td>R.S. DEVCON</td>\n",
       "      <td>0.814227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VYOM INFRASTRUCTURES</td>\n",
       "      <td>VYOM INFRASTRUCTURES &amp; PROJECTS</td>\n",
       "      <td>0.915835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>GE INDIA EXPORTS</td>\n",
       "      <td>GE T&amp;D INDIA</td>\n",
       "      <td>0.861518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SUNLORD PROJECTS</td>\n",
       "      <td>SUNLORD IMPEX</td>\n",
       "      <td>0.800032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>BHOLE BABA MILK FOOD INDUSTRIES</td>\n",
       "      <td>BHOLE BABA MILK FOOD INDUSTRIES(DHOLPUR)</td>\n",
       "      <td>0.864553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>ESS ESS EXIM</td>\n",
       "      <td>ESS N ESS BUILDCON</td>\n",
       "      <td>0.905051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>S.N. MILK PRODUCTS</td>\n",
       "      <td>BEST MILK PRODUCTS</td>\n",
       "      <td>0.805717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>DTC INDIA</td>\n",
       "      <td>DTC &amp; ORS</td>\n",
       "      <td>0.905382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>DEV DUTT ENGINEERS</td>\n",
       "      <td>DEV DUTT CONSTRUCTIONS</td>\n",
       "      <td>0.813535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>ARC FINANCIAL SERVICES</td>\n",
       "      <td>ARC SERVICES</td>\n",
       "      <td>0.803548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>BHOLE BABA MILK FOOD INDUSTRIES(DHOLPUR)</td>\n",
       "      <td>BHOLE BABA MILK FOOD INDUSTRIES</td>\n",
       "      <td>0.864553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>V.M.S. APPARELS</td>\n",
       "      <td>R.H. APPARELS (INDIA)</td>\n",
       "      <td>0.914704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    left_side  \\\n",
       "141                         SEARCH BUILD TECH   \n",
       "231               RAMA SANDESH DEVELOPERS PVT   \n",
       "827          KULLU VALLEY LEISURE RESORTS PVT   \n",
       "183                SEVEN HEAVEN CONSTRUCTIONS   \n",
       "310                                 ABB POWER   \n",
       "592             ORANGE ASHOK NORTH WIND POWER   \n",
       "652                     K.B. POLYCHEM (INDIA)   \n",
       "620                            AMBIENCE IMPEX   \n",
       "126                                RAJ DEVCON   \n",
       "21                       VYOM INFRASTRUCTURES   \n",
       "875                          GE INDIA EXPORTS   \n",
       "60                           SUNLORD PROJECTS   \n",
       "679           BHOLE BABA MILK FOOD INDUSTRIES   \n",
       "287                              ESS ESS EXIM   \n",
       "677                        S.N. MILK PRODUCTS   \n",
       "535                                 DTC INDIA   \n",
       "283                        DEV DUTT ENGINEERS   \n",
       "442                    ARC FINANCIAL SERVICES   \n",
       "570  BHOLE BABA MILK FOOD INDUSTRIES(DHOLPUR)   \n",
       "236                           V.M.S. APPARELS   \n",
       "\n",
       "                                   right_side  similairity  \n",
       "141                         SEARCH TECH INDIA     0.814534  \n",
       "231                    RAMA SANDESH BUILDWELL     0.812467  \n",
       "827          KULLU VALLEY LEISURE RESORTS ...     0.957491  \n",
       "183                        SEVEN HEAVEN IMPEX     0.841584  \n",
       "310                                 ABB INDIA     0.827938  \n",
       "592                   ORANGE ASHOK WIND POWER     0.879980  \n",
       "652                              P D POLYCHEM     0.937767  \n",
       "620                            AMBIENCE INDIA     0.832516  \n",
       "126                               R.S. DEVCON     0.814227  \n",
       "21            VYOM INFRASTRUCTURES & PROJECTS     0.915835  \n",
       "875                              GE T&D INDIA     0.861518  \n",
       "60                              SUNLORD IMPEX     0.800032  \n",
       "679  BHOLE BABA MILK FOOD INDUSTRIES(DHOLPUR)     0.864553  \n",
       "287                        ESS N ESS BUILDCON     0.905051  \n",
       "677                        BEST MILK PRODUCTS     0.805717  \n",
       "535                                 DTC & ORS     0.905382  \n",
       "283                    DEV DUTT CONSTRUCTIONS     0.813535  \n",
       "442                              ARC SERVICES     0.803548  \n",
       "570           BHOLE BABA MILK FOOD INDUSTRIES     0.864553  \n",
       "236                     R.H. APPARELS (INDIA)     0.914704  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "matches_df = get_matches_df(matches, clean_company_names, top=1000)\n",
    "matches_df = matches_df[matches_df['similairity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
